{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/098Steve/Jupyter/blob/main/HuggingFace_Ladder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The HuggingFace Ladder  \n",
        "- Write code, tweak and experiment with each Level of these 16 pipelines abilities. You might only complete Levels One to Three, that's expected!  \n",
        "- Find out the parameters/models in the code, then tweak them to change output. Try different models, try different inputs.    \n",
        "- LLMs may be used for understanding, but not for code, unless you have spent 10 minutes trying to solve your problem.  \n",
        "- Have a Presenter and work together  \n",
        "\n",
        "Level One  \n",
        "1\tsentiment-analysis  \n",
        "\n",
        "Level Two (pick two)  \n",
        "2\ttext-classification  \n",
        "3\tzero-shot-classification  \n",
        "4\tfill-mask  \n",
        "5\tner  \n",
        "\n",
        "Level Three  \n",
        "6\ttext-generation (try different models, tweak parameters)\n",
        "\n",
        "Level Four (pick two)  \n",
        "7\tsummarization  \n",
        "8\ttranslation  \n",
        "9\tquestion-answering  \n",
        "10\tconversational  \n",
        "\n",
        "Level Five - advanced (pick one)  \n",
        "11\timage-classification  \n",
        "12\timage-to-text  \n",
        "13\tautomatic-speech-recognition  \n",
        "14\ttext-to-speech  \n",
        "15\ttable-question-answering  \n",
        "16\tdocument-question-answering  "
      ],
      "metadata": {
        "id": "M2Z5-6xE_uEn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6M1K0WZ-k85"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "-nXOmetF8ofs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Sentiment Analysis - get it working\n",
        "sentiment = pipeline(\"sentiment-analysis\")\n",
        "print(sentiment(\"I love baking ciabatta!\"))\n"
      ],
      "metadata": {
        "id": "fNmqVnNGU_pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis - try some interesting inputs\n",
        "sentiment = pipeline(\"sentiment-analysis\")\n",
        "print(sentiment(\"It was meh\"))"
      ],
      "metadata": {
        "id": "cJC2sJ30WGj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis - try other interesting inputs. Edit additional parameters\n",
        "sentiment = pipeline(\"sentiment-analysis\")\n",
        "print(sentiment(\"I rly enjyed tha thing wot I did!\", top_k=None))"
      ],
      "metadata": {
        "id": "xPTP1szbWGht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis - try different models. This one gives a star rating\n",
        "sentiment = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "print(sentiment(\"I highly recommend this product!\", top_k=4))"
      ],
      "metadata": {
        "id": "cQAQ-nXDWqMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis - try different models. This one gives a star rating\n",
        "sentiment = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "print(sentiment(\"Five stars!\"))\n",
        "print(sentiment(\"Fiv stars!\"))"
      ],
      "metadata": {
        "id": "HARdmtAlXwNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level Two"
      ],
      "metadata": {
        "id": "txt0hxrR8sOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Text Classification\n",
        "classifier = pipeline(\"text-classification\")\n",
        "print(classifier(\"This email looks like spam.\"))\n"
      ],
      "metadata": {
        "id": "W9LBD5EnVALN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Zero-shot Classification\n",
        "zero_shot = pipeline(\"zero-shot-classification\")\n",
        "print(zero_shot(\"Hugging Face makes AI easier.\", candidate_labels=[\"education\", \"finance\", \"sports\"]))\n"
      ],
      "metadata": {
        "id": "Jh9i7xNVVA-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fill Mask\n",
        "fill = pipeline(\"fill-mask\")\n",
        "print(fill(\"The capital of France is <mask>.\"))\n"
      ],
      "metadata": {
        "id": "a1QCj847VErm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Named Entity Recognition\n",
        "ner = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
        "print(ner(\"Elon Musk founded SpaceX in 2002.\"))\n"
      ],
      "metadata": {
        "id": "7_6VWDtAVEPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level Three"
      ],
      "metadata": {
        "id": "0Xa075GN8tX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Text Generation\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "print(generator(\"Once upon a time,\", max_new_tokens=20))\n"
      ],
      "metadata": {
        "id": "tQG5n3uRVDtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level Four"
      ],
      "metadata": {
        "id": "uDWdqD5g8xdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Summarisation\n",
        "summariser = pipeline(\"summarization\")\n",
        "text = \"\"\"Hugging Face is a company that develops tools for building applications using machine learning.\n",
        "It is known for its Transformers library which provides thousands of pre-trained models for NLP.\"\"\"\n",
        "print(summariser(text))\n"
      ],
      "metadata": {
        "id": "MVp_DHp3VDPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Translation\n",
        "translator = pipeline(\"translation_en_to_fr\")\n",
        "print(translator(\"Machine learning is fascinating.\"))\n"
      ],
      "metadata": {
        "id": "57FV-vbrVCwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Question Answering\n",
        "qa = pipeline(\"question-answering\")\n",
        "print(qa({\n",
        "    \"context\": \"The Eiffel Tower is located in Paris. It was built in 1889.\",\n",
        "    \"question\": \"Where is the Eiffel Tower?\"\n",
        "}))\n"
      ],
      "metadata": {
        "id": "vPShsWKpVCI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Conversational\n",
        "from transformers import Conversation\n",
        "chatbot = pipeline(\"conversational\")\n",
        "conv = Conversation(\"Hi there! How can I help you today?\")\n",
        "print(chatbot(conv))\n"
      ],
      "metadata": {
        "id": "Xn7YOpOwVBrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Level Five"
      ],
      "metadata": {
        "id": "a4jyEyIJ8yt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced methods - these may require code tweaks and edits"
      ],
      "metadata": {
        "id": "NSV1gGHKVv-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch torchvision torchaudio pandas pillow"
      ],
      "metadata": {
        "id": "k59PWYGi-wAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Classification\n",
        "from PIL import Image\n",
        "img = Image.open(\"path_to_image.jpg\")\n",
        "image_classifier = pipeline(\"image-classification\")\n",
        "print(image_classifier(img))\n",
        "\n",
        "# Image to Text (e.g. captioning)\n",
        "image_to_text = pipeline(\"image-to-text\")\n",
        "print(image_to_text(img))\n",
        "\n",
        "# Automatic Speech Recognition\n",
        "speech = pipeline(\"automatic-speech-recognition\")\n",
        "print(speech(\"path_to_audio.wav\"))\n",
        "\n",
        "# Table Question Answering\n",
        "import pandas as pd\n",
        "table_qa = pipeline(\"table-question-answering\")\n",
        "data = pd.read_csv(\"example_table.csv\")  # Must be a DataFrame\n",
        "print(table_qa(question=\"What is the total revenue?\", table=data))\n",
        "\n",
        "# Document Question Answering\n",
        "doc_qa = pipeline(\"document-question-answering\")\n",
        "print(doc_qa(question=\"What is the invoice number?\", image=\"invoice.pdf\"))\n"
      ],
      "metadata": {
        "id": "is9z8oAH-yOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IvpFrDNFZW_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "alV-GVzoZW9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "2arlOdb1Zgpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio"
      ],
      "metadata": {
        "id": "7P6jLPse81Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load sentiment pipeline with star-rating model\n",
        "sentiment = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# Function to wrap the model output\n",
        "def analyze_sentiment(text):\n",
        "    result = sentiment(text)[0]\n",
        "    return f\"{result['label']} ({result['score']:.2f} confidence)\"\n",
        "\n",
        "# Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=analyze_sentiment,\n",
        "    inputs=gr.Textbox(lines=3, placeholder=\"Type a review or sentence here...\"),\n",
        "    outputs=gr.Textbox(label=\"Sentiment Result\"),\n",
        "    title=\"ðŸŒŸ Star Rating Sentiment Analysis\",\n",
        "    description=\"Uses a Hugging Face model that returns star ratings from 1 to 5 based on input text sentiment.\"\n",
        ")\n",
        "\n",
        "demo.launch()\n",
        "# Use Gradio for MVP, POC user interfaces with non-sensitive data\n",
        "# If deploying fully, you may wish to use a cloud service or streamlit\n",
        "## Make sure you speak with your IT/software/DevOps/cybersecurity teams before deploying anything"
      ],
      "metadata": {
        "id": "bcnacFlmZl_y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}