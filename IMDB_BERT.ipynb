{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/098Steve/Jupyter/blob/main/IMDB_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook fine-tunes BERT on the IMDB positive/negative reviews dataset\n",
        "\n",
        "Please make this your own for editing: click File > Save a Copy in Drive\n",
        "\n",
        "Set the runtime as T4 GPU. Click the triangle arrow top right, click Change Runtime Type, Select T4 GPU. You may need to reload the notebook\n",
        "\n",
        "Work through to understand each step. Use Google and an LLM to help you"
      ],
      "metadata": {
        "id": "Hb4t5j_qnqa_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wqhsgbn3VKQY"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Step 0: Install required libraries (only run once in Colab)\n",
        "!pip install datasets -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 1: Imports\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "iWeERSfvVMg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 2: Load the IMDB dataset and take a small subset for quick training\n",
        "dataset = load_dataset(\"imdb\", split={\"train\": \"train[:2000]\", \"test\": \"test[:1000]\"})\n",
        "small_train = dataset[\"train\"]\n",
        "small_test = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "NeAVCMX6VNVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 3: Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "c6Qdv99ZVSX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 4: Tokenise text\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "train_enc = small_train.map(tokenize, batched=True)\n",
        "test_enc = small_test.map(tokenize, batched=True)"
      ],
      "metadata": {
        "id": "OzrYWPvgVR3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 5: Set PyTorch format\n",
        "train_enc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_enc.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "metadata": {
        "id": "Jm62g1xiVRWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 6: Load model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "id": "XvqklGmvVQxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 7: Define metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}"
      ],
      "metadata": {
        "id": "YaKKAk9BVQKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 8: Training arguments (tuned for Colab + T4 GPU)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-imdb\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=10,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=False,\n",
        "    report_to=\"none\",  # turn off wandb\n",
        ")"
      ],
      "metadata": {
        "id": "ImOphp7tVPeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 9: Train\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_enc,\n",
        "    eval_dataset=test_enc,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "PJ2wBvJyVO5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# after trainer.train()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "q0u_uPZBhOfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 10: Evaluate\n",
        "metrics = trainer.evaluate()\n",
        "print(\"‚úÖ Test Accuracy:\", metrics[\"eval_accuracy\"])"
      ],
      "metadata": {
        "id": "JSAZKpGWVOK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 11: Make a predictive function\n",
        "def predict_sentiment(text):\n",
        "    # Tokenise and immediately move tensors to the same device as model\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=512\n",
        "    ).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "        confidence = probs[0, pred].item()\n",
        "\n",
        "    sentiment = \"üëç Positive\" if pred == 1 else \"üëé Negative\"\n",
        "    print(f\"Sentiment: {sentiment} ({confidence:.2%} confidence)\")"
      ],
      "metadata": {
        "id": "G_MxyrDpVWfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"I loved the movie.\")\n",
        "predict_sentiment(\"It was boring, slow, and way too long. I wouldn't recommend it.\")"
      ],
      "metadata": {
        "id": "i8pxrP1MVcwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6NwEGve2VvRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well done for getting to the end of this Notebook!\n",
        "\n",
        "How was the performance of the model?\n",
        "\n",
        "Maybe you can spot the error that causes the performance to be low... Easily fixed!"
      ],
      "metadata": {
        "id": "ew9h4M5Ln8Ye"
      }
    }
  ]
}