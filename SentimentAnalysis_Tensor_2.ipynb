{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/098Steve/Jupyter/blob/main/SentimentAnalysis_Tensor_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMDB Movie Sentiment Analysis**\n",
        "\n",
        "The IMDB dataset consists of 50000 binary reviews, which are evenly split into positive and\n",
        "negative opinions. Each review consists of a list of integers, where each integer represents a\n",
        "word in that review. Keras has the dataset within its library so we can just load it directly from\n",
        "Keras"
      ],
      "metadata": {
        "id": "-2jl7Qu0t9gQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29q9m-c-3UaA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, layers, models, preprocessing, Model\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialise parameters\n",
        "max_len =200\n",
        "n_words =10000\n",
        "dim_embedding = 256\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 500"
      ],
      "metadata": {
        "id": "gA6IeX00FPS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFtZp6deFP-2"
      },
      "outputs": [],
      "source": [
        "#A function to load the dataset\n",
        "def load_data():\n",
        "  #load_data\n",
        "  (X_train, y_train),(X_test, y_test) = datasets.imdb.load_data(num_words=n_words)\n",
        "  #pad sequence with max_len\n",
        "  X_train= preprocessing.sequence.pad_sequences (X_train, maxlen=max_len)\n",
        "  X_test= preprocessing.sequence.pad_sequences (X_test, maxlen=max_len)\n",
        "  return (X_train, y_train), (X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now a function to build the model\n",
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  #Input: eEmbedding layer\n",
        "  #The model will take as imput an integer matrix of size (batch, input_length)\n",
        "  #The model will output dimension (input_length, dim_embedding)\n",
        "  #The largest integer in the input should be no larger than n_words (vocabulary size)\n",
        "  model.add (layers.Embedding(n_words, dim_embedding))\n",
        "  model.add (layers.Dropout(0.3))\n",
        "  #takes the maximum value  from each of the n_words features.\n",
        "  model.add(layers.GlobalMaxPooling1D())\n",
        "  model.add (layers.Dense(128, activation = 'relu'))\n",
        "  model.add (layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(1, activation= 'sigmoid' ))\n",
        "  return model"
      ],
      "metadata": {
        "id": "xUfuT1to-vYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Now we build and fit the model\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = load_data()\n",
        "model = build_model()\n",
        "model.summary()\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"] )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "swObQ_2VBj7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next fit and evaluate it\n",
        "train_score = model.fit(X_train, y_train, epochs = EPOCHS, batch_size = BATCH_SIZE, validation_data = (X_test, y_test))\n",
        "test_score = model.evaluate(X_test, y_test, batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "id": "x4UGlhJfvMWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below will show what keys are available in history dictionary object test_score\n",
        "\n",
        "train_score.history.keys()\n",
        "\n"
      ],
      "metadata": {
        "id": "gjp1oqz4Kjjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312e488b-fc98-4331-cd75-0d762615b49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# variables for visualizing losses and accuracy\n",
        "\n",
        "\n",
        "train_loss = train_score.history['loss']\n",
        "val_loss   = train_score.history['val_loss']\n",
        "train_acc  = train_score.history['accuracy']\n",
        "val_acc    = train_score.history['val_accuracy']\n",
        "xc         = range(EPOCHS)\n",
        "\n"
      ],
      "metadata": {
        "id": "rod0OsyqQGh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare loss\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(xc, train_loss, color=\"red\", label=\"Training Loss\")\n",
        "plt.plot(xc, val_loss, color =\"blue\", label = \"Validation Loss\")\n",
        "plt.title(\"Training Loss and Validation Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show"
      ],
      "metadata": {
        "id": "hMdfGY7dcmwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare accuracy\n",
        "plt.figure()\n",
        "plt.plot(xc, train_acc, color=\"red\", label =\"Training Accuracy\")\n",
        "plt.plot(xc, val_acc, color =\"blue\", label = \"Validation Accuracy\")\n",
        "plt.title(\"Training Acuracy and Validation Accuracy\")\n",
        "plt.xlabel ('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "l_RJuuwCcbpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print final training loss\n",
        "\n",
        "print (\"Training:\",  \"Loss=\", train_loss[19] , \"Accuracy=\", train_acc[19] )"
      ],
      "metadata": {
        "id": "kOB2ZVVZSv8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bf8b0a-5b7e-4f63-c505-e392e5670fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: Loss= 0.00608218926936388 Accuracy= 0.9988800287246704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print testing loss and accuracy\n",
        "\n",
        "print (\"Testing:\",  \"Loss=\", test_score[0] , \"Accuracy=\", test_score[1] )"
      ],
      "metadata": {
        "id": "9yTfdsLyT2Xx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babc2f13-9380-4a8e-aa6f-ebac713a720d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: Loss= 0.4959609806537628 Accuracy= 0.8514800071716309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you think the model is overfitted?\n",
        "What is overfitting?"
      ],
      "metadata": {
        "id": "m1JtgfgpcdOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's explore the  data and do some prediction"
      ],
      "metadata": {
        "id": "fGkNs3B4cpzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's look at some data\n",
        "\n",
        "X_train[1:4]"
      ],
      "metadata": {
        "id": "uDvJ_cOwdzlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that each word is represented by a number.  The movies data set has a word index so that we can see which number represents which word."
      ],
      "metadata": {
        "id": "_2H8K57ZgBEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The movies dataset has a word-index\n",
        "word_index = datasets.imdb.get_word_index()\n",
        "#Let's look at the words in the word index\n",
        "word_index.items()\n",
        "\n"
      ],
      "metadata": {
        "id": "IcSFA9iIlggE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reverse the key and value from the dictionary so that we can look up numbers to see words\n",
        "reverse_word_index = dict([(value, key) for (key,value) in word_index.items()])\n",
        "reverse_word_index.items()\n",
        "\n"
      ],
      "metadata": {
        "id": "RDhxQPD9mF1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function takes two arguments. The first one (n) denotes an integer referring to the\n",
        "nth review in a set. The second argument defines whether the nth review is taken from our\n",
        "training set or our test data. Then it simply returns the string version of the review we specify. The i-3 is an offset because positions 0,1 and 2 are used for index in a sequence."
      ],
      "metadata": {
        "id": "xoTMvZqRnISX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decode_review (n, split='train'):\n",
        "  if split=='train':\n",
        "    decoded_review=' '.join([reverse_word_index.get(i-3,'?') for i in X_train[n]])\n",
        "  elif split=='test':\n",
        "    decoded_review=' '.join([reverse_word_index.get(i-3,'?') for i in X_test[n]])\n",
        "  return decoded_review\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6onxROMQnhYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the following code prints the training label and decodes a review\n",
        "print('Training label:', y_test[4])\n",
        "review =decode_review(5,split='test')\n",
        "review"
      ],
      "metadata": {
        "id": "yRQLxrWgnpWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict the whole test dataset\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "qo9nlslotOxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "9S_I2D9BOnSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set boundaries for when a review is positive and when it is negative\n",
        "\n",
        "def gauge_predictions(n):\n",
        "  if (predictions[n]<=0.4) and (y_test[n]==0):\n",
        "    print('Network correctly predicts that review {} is negative'.format(n))\n",
        "  elif (predictions[n] >0.7) and (y_test[n]==1):\n",
        "    print('Network correctly predicts that review {} is positive'.format(n))\n",
        "  elif (predictions[n]>0.7) and (y_test[n]==0):\n",
        "    print('Network incorrectly predicts that review {}is positive'.format(n))\n",
        "  elif (predictions[n]<=0.4) and (y_test[n]==1):\n",
        "    print('Network incorrectly predicts that review {} is negative'.format(n))\n",
        "  else:\n",
        "    print('Network is not so sure. Review {} has a probability of positive score of {}'.format(n))"
      ],
      "metadata": {
        "id": "hu7114x9sBTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_predictions(n):\n",
        "  return gauge_predictions(n), predictions[n], y_test[n], decode_review(n, split='test')"
      ],
      "metadata": {
        "id": "j4x4O7elsXl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the verify predictions function to see some reviews and whether they were predicted as positive or negative"
      ],
      "metadata": {
        "id": "JV_ICVT_h44j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "verify_predictions(7)\n"
      ],
      "metadata": {
        "id": "aEbaz-B4sxiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count number of predictions where the model is not sure\n",
        "\n",
        "count=0\n",
        "x=0\n",
        "while x < 25000:\n",
        "  if (predictions[x] > 0.4) and (predictions[x] <= 0.7):\n",
        "    count+=1\n",
        "  x+=1\n",
        "print(count)\n"
      ],
      "metadata": {
        "id": "KKlLQHSnsboM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}